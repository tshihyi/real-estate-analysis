{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J754l3jLLdu"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!apt-get update  # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp / usr/lib/chromium-browser/chromedriver / usr/bin\n",
        "\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffpa0YqB-Rco"
      },
      "source": [
        "Web Crawler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6bVxwLFRYIA",
        "outputId": "c31f3bb9-b30d-4e00-af86-5710296b5273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation successful !\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium import webdriver\n",
        "import sys\n",
        "sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_prefs = {\"download.default_directory\": './content/drive'}\n",
        "chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
        "driver = webdriver.Chrome('chromedriver', options=chrome_options)\n",
        "url = \"https://plvr.land.moi.gov.tw/DownloadOpenData\"\n",
        "\n",
        "\n",
        "xpath_list = [\n",
        "    \"//select[@id='historySeason_id']/option[@value='108S2']\",\n",
        "    \"//select[@id='fileFormatId']/option[@value='csv']\",  # csv\n",
        "    \"//input[@id='downloadTypeId2']\",  # 進階\n",
        "    \"//input[@value='A_lvr_land_A']\",  # 台北\n",
        "    \"//input[@value='F_lvr_land_A']\",  # 新北\n",
        "    \"//input[@value='H_lvr_land_A']\",  # 桃園\n",
        "    \"//input[@value='B_lvr_land_A']\",  # 台中\n",
        "    \"//input[@value='E_lvr_land_A']\",  # 高雄\n",
        "    \"//input[@id='downloadBtnId']\"  # 下載\n",
        "]\n",
        "\n",
        "\n",
        "def clawer():\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver, 20).until(\n",
        "        EC.element_to_be_clickable((By.ID, 'ui-id-2'))).click()\n",
        "    for xpath in xpath_list:\n",
        "        WebDriverWait(driver, 20).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
        "    print(\"Operation successful !\")\n",
        "    time.sleep(60)\n",
        "\n",
        "\n",
        "try:\n",
        "    clawer()\n",
        "except Exception:\n",
        "    driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MRAVH34DsP64"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from functools import reduce  # For Python 3.x\n",
        "\n",
        "zip_file = ZipFile('./content/drive/download.zip')\n",
        "\n",
        "df_list = [\n",
        "    pd.read_csv(zip_file.open('A_lvr_land_A.csv')),\n",
        "    pd.read_csv(zip_file.open('F_lvr_land_A.csv')),\n",
        "    pd.read_csv(zip_file.open('H_lvr_land_A.csv')),\n",
        "    pd.read_csv(zip_file.open('B_lvr_land_A.csv')),\n",
        "    pd.read_csv(zip_file.open('E_lvr_land_A.csv'))\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdsXYpJ0-JKJ"
      },
      "source": [
        "Data clean and transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLQ51QwpmJh",
        "outputId": "62ae72a8-8259-4b99-8b8a-d71789c7a664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        33\n",
            "1        13\n",
            "2         0\n",
            "3         4\n",
            "4         5\n",
            "         ..\n",
            "49637     5\n",
            "49638     2\n",
            "49639    14\n",
            "49640     2\n",
            "49641     0\n",
            "Name: floor_Num, Length: 49642, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def covert_num(floor_name):\n",
        "    result = 0\n",
        "    if isinstance(floor_name, int):\n",
        "        return floor_name\n",
        "\n",
        "    if isinstance(floor_name, float):\n",
        "        result = int(floor_name)\n",
        "        return result\n",
        "\n",
        "    if(floor_name.endswith('層')):\n",
        "        floor_name = floor_name[:-1]\n",
        "    # List of words\n",
        "    num_list = {\"一\": 1, \"二\": 2, \"三\": 3, \"四\": 4, \"五\": 5,\n",
        "                \"六\": 6, \"七\": 7, \"八\": 8, \"九\": 9, \"十\": 10}\n",
        "\n",
        "    for i in range(0, len(floor_name)):\n",
        "        for k in num_list:\n",
        "            if len(floor_name) == 1:\n",
        "                if (k == floor_name[i]):\n",
        "                    result = num_list[k]\n",
        "            elif len(floor_name) == 2:\n",
        "                if (k == floor_name[0]):\n",
        "                    result = num_list[k] + num_list[floor_name[1]]\n",
        "                else:\n",
        "                    result = num_list[floor_name[0]] * 10\n",
        "            elif len(floor_name) == 3:\n",
        "                if (k == floor_name[1]):\n",
        "                    result = num_list[floor_name[0]] * \\\n",
        "                        10 + num_list[floor_name[2]]\n",
        "                else:\n",
        "                    result = 0\n",
        "        return result\n",
        "\n",
        "\n",
        "def convert_western_date(date):\n",
        "    if len(date) > 0:\n",
        "        date = date.replace(\n",
        "            date[0:3], str(int(date[0:3])+1911))\n",
        "        date = date[0:4] + \"-\" + date[4:6] + \"-\" + date[6:8]\n",
        "    return date\n",
        "\n",
        "\n",
        "def clean_data(data_set, cityName):\n",
        "    data_set = data_set.drop([0])\n",
        "    data_set = data_set.fillna(0)\n",
        "\n",
        "    trans_dict = {\n",
        "        '主建物面積': str,\n",
        "        '附屬建物面積': str,\n",
        "        '陽台面積': str,\n",
        "        '車位類別': str,\n",
        "        '移轉層次': str,\n",
        "        '總樓層數': str,\n",
        "        '主要用途': str,\n",
        "        '主要建材': str,\n",
        "        '建築完成年月': str,\n",
        "        '備註': str,\n",
        "        '單價元平方公尺': str,\n",
        "        '都市土地使用分區': str,\n",
        "        '非都市土地使用分區': str,\n",
        "        '非都市土地使用編定': str\n",
        "    }\n",
        "    # convert dataype to string or integer\n",
        "    for item in trans_dict.keys():\n",
        "        data_set[item] = data_set[item].astype(trans_dict[item])\n",
        "\n",
        "    # special processing\n",
        "    data_set['交易年月日'] = data_set['交易年月日'].apply(convert_western_date)\n",
        "    data_set['floor_Num'] = data_set['總樓層數'].apply(covert_num)\n",
        "    data_set.insert(0, 'city', cityName)\n",
        "\n",
        "    return data_set\n",
        "\n",
        "\n",
        "df = pd.concat([\n",
        "    clean_data(df_list[0], \"台北市\"),\n",
        "    clean_data(df_list[1], \"新北市\"),\n",
        "    clean_data(df_list[2], \"桃園市\"),\n",
        "    clean_data(df_list[3], \"台中市\"),\n",
        "    clean_data(df_list[4], \"高雄市\")\n",
        "],\n",
        "    axis=0,\n",
        "    join=\"outer\",\n",
        "    ignore_index=True)\n",
        "\n",
        "print(df['floor_Num'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg_hKUnavF84"
      },
      "source": [
        "Convert to Spark DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBPTPzKTvA5S",
        "outputId": "405862ec-b4a9-4c12-999c-8b4cb1c459db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total data count:  49642\n"
          ]
        }
      ],
      "source": [
        "# Create PySpark SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkMergeDataSet\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Convert Pandas DataFrame to Spark DataFrame\n",
        "sparkdf_list = [\n",
        "    spark.createDataFrame(clean_data(df_list[0], \"台北市\")),\n",
        "    spark.createDataFrame(clean_data(df_list[1], \"新北市\")),\n",
        "    spark.createDataFrame(clean_data(df_list[2], \"桃園市\")),\n",
        "    spark.createDataFrame(clean_data(df_list[3], \"台中市\")),\n",
        "    spark.createDataFrame(clean_data(df_list[4], \"高雄市\"))\n",
        "]\n",
        "\n",
        "spark_df = reduce(DataFrame.unionAll, sparkdf_list)\n",
        "\n",
        "print(\"total data count: \", spark_df.count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECp6HSKtEnGo"
      },
      "source": [
        "- Merge Dataframes by Pyspark\n",
        "- Filter data by conditions\n",
        "- Generate JSON files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JI9J2uZD9-U6"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import json\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "query_df = spark_df.where('`主要用途` == \"住家用\"')\\\n",
        "    .where('`建物型態` like \"住宅大樓%\"')\\\n",
        "    .where('floor_num >= 13')\\\n",
        "    .sort(desc(\"交易年月日\"))\n",
        "\n",
        "query_df = query_df.drop(\"floor_num\")\n",
        "pandas_df = query_df.toPandas()\n",
        "records = pandas_df.values.tolist()\n",
        "\n",
        "table = {}\n",
        "for column in records:\n",
        "    city = column[0]\n",
        "    district = column[1]\n",
        "    date = column[8]\n",
        "    building_state = column[2]\n",
        "    purpose = column[13]\n",
        "    floors = column[12]\n",
        "\n",
        "    if not city in table.keys():\n",
        "        table[city] = {}\n",
        "    if not date in table[city].keys():\n",
        "        table[city][date] = []\n",
        "    table[city][date].append({\n",
        "        \"鄉鎮市區\": district,\n",
        "        \"建物型態\": building_state,\n",
        "        \"主要用途\": purpose,\n",
        "        \"總樓層數\": floors\n",
        "    })\n",
        "\n",
        "result = []\n",
        "\n",
        "for city, date_table in table.items():\n",
        "    time_slots = []\n",
        "    for date, events in date_table.items():\n",
        "        time_slots.append({\n",
        "            \"date\": date,\n",
        "            \"events\": events\n",
        "        })\n",
        "\n",
        "    result.append({\n",
        "        \"city\": city,\n",
        "        \"time_slots\": time_slots\n",
        "    })\n",
        "\n",
        "with io.open('result-part1.json', 'w', encoding='utf-8') as f:\n",
        "    for item in result[:2]:\n",
        "        f.write(json.dumps(item, ensure_ascii=False, indent=2))\n",
        "\n",
        "with io.open('result-part2.json', 'w', encoding='utf-8') as f:\n",
        "    for item in result[2:]:\n",
        "        f.write(json.dumps(item, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DuHGRYOtGdE"
      },
      "source": [
        "dataFrame save to SQLite3 for creating RESTful API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9HKaPwIs8xG",
        "outputId": "2faf08a0-45c6-4865-bbbd-01b8b9318763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   count(*)\n",
            "0     49642\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "# create db\n",
        "conn = sqlite3.connect('land.db')\n",
        "cursor = conn.cursor()\n",
        "conn.commit()\n",
        "\n",
        "# replace: Drop the table before inserting new values.\n",
        "df.to_sql('land_txn_log', conn, if_exists='replace', index=False)\n",
        "us_df = pd.read_sql(\"SELECT count(*) FROM land_txn_log;\", conn)\n",
        "print(us_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "land_info.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
